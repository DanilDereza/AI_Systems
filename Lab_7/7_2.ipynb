{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f07d4a-f35c-4914-a7d7-6055149a498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Bidirectional, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0e1821-ad7a-44b9-8100-6106360bde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1416b0ef-8dbd-473f-bd21-14c049c33fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    bag_of_words = data[\"BoW\"]\n",
    "    bigrams = data[\"bigrams\"]\n",
    "    fourgrams = data[\"fourgrams\"]\n",
    "    return bag_of_words, bigrams, fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea1be62-c636-4af0-a633-48b40addeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(bag_of_words):\n",
    "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(bag_of_words.items())}\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def convert_to_sequences(ngrams, vocab):\n",
    "    sequences = []\n",
    "    for gram in ngrams:\n",
    "        if all(word in vocab for word in gram):\n",
    "            sequences.append([vocab[word] for word in gram])\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def prepare_data(ngrams_sequences, n):\n",
    "    X, Y = [], []\n",
    "    for gram in ngrams_sequences:\n",
    "        X.append(gram[:-1])\n",
    "        Y.append(gram[-1])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8bc547-191f-48a0-9ffd-984d54427f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(vocab_size, embedding_dim, n):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=n-1),\n",
    "        SimpleRNN(256, activation=\"tanh\", return_sequences=False),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lstm_model(vocab_size, embedding_dim, n):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=n-1),\n",
    "        LSTM(256, activation=\"tanh\", return_sequences=False),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_gru_model(vocab_size, embedding_dim, n):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=n-1),\n",
    "        GRU(256, activation=\"tanh\", return_sequences=False),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_dense_model(vocab_size):\n",
    "    model = Sequential([\n",
    "        Dense(512, input_dim=1, activation='tanh'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccdba22c-fc69-4c29-a309-163da6d53efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, vocab=None, threshold=None, bow=False):\n",
    "    preds = model.predict(X_test)\n",
    "    if threshold:\n",
    "        preds_binary = (preds > threshold).astype(np.int32)\n",
    "    else:\n",
    "        preds_binary = preds.argmax(axis=-1)\n",
    "\n",
    "    metrics = {}\n",
    "    if vocab:\n",
    "        inv_vocab = {idx: word for word, idx in vocab.items()}\n",
    "        preds_text = [inv_vocab.get(idx, \"<UNK>\") for idx in preds_binary]\n",
    "        metrics[\"Generated Text\"] = \" \".join(preds_text)\n",
    "    else:\n",
    "        if bow: Y_test = Y_test.argmax(axis=-1)\n",
    "        metrics.update({\n",
    "            \"Accuracy\": accuracy_score(Y_test, preds_binary),\n",
    "            \"Precision\": precision_score(Y_test, preds_binary, average='weighted'),\n",
    "            \"Recall\": recall_score(Y_test, preds_binary, average='weighted'),\n",
    "            \"F1-Score\": f1_score(Y_test, preds_binary, average='weighted'),\n",
    "        })\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351f38fd-b6d1-449a-94a9-aab1fa457ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a430b24-5af2-44f9-bcdd-ed5d5a3c47d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: [('корабль', 255), ('человек', 242), ('планета', 215), ('сторона', 206), ('мой', 189), ('канваля', 189), ('рука', 180), ('новый', 170), ('баронство', 169), ('тисара', 166)]\n",
      "\n",
      "2-граммы: [('алекс', 'каменеть'), ('каменеть', 'макс'), ('макс', 'вольф'), ('вольф', 'наёмник'), ('наёмник', 'глава'), ('глава', 'станция'), ('станция', 'технический'), ('технический', 'обслуживание'), ('обслуживание', 'бринг'), ('бринг', 'лиманский')]\n",
      "\n",
      "4-граммы: [('алекс', 'каменеть', 'макс', 'вольф'), ('каменеть', 'макс', 'вольф', 'наёмник'), ('макс', 'вольф', 'наёмник', 'глава'), ('вольф', 'наёмник', 'глава', 'станция'), ('наёмник', 'глава', 'станция', 'технический'), ('глава', 'станция', 'технический', 'обслуживание'), ('станция', 'технический', 'обслуживание', 'бринг'), ('технический', 'обслуживание', 'бринг', 'лиманский'), ('обслуживание', 'бринг', 'лиманский', 'союз'), ('бринг', 'лиманский', 'союз', 'приграничный')]\n"
     ]
    }
   ],
   "source": [
    "path = \"result_lab2/text_structures2.pkl\"\n",
    "bag_of_words, bigrams, fourgrams = load_data(path)\n",
    "\n",
    "print(\"BoW:\", list(bag_of_words.items())[:10])\n",
    "print(\"\\n2-граммы:\", bigrams[:10])\n",
    "print(\"\\n4-граммы:\", fourgrams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fb5634-5145-4bb4-abd5-c203d2fa51ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Словарь: [('корабль', 1), ('человек', 2), ('планета', 3), ('сторона', 4), ('мой', 5), ('канваля', 6), ('рука', 7), ('новый', 8), ('баронство', 9), ('тисара', 10)]\n"
     ]
    }
   ],
   "source": [
    "vocab = create_vocab(bag_of_words)\n",
    "vocab_size = len(vocab) + 1\n",
    "print(\"\\nСловарь:\", list(vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eaabee-78b2-4b88-aa94-e814af10c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_sequences = convert_to_sequences(bigrams, vocab)\n",
    "fourgrams_sequences = convert_to_sequences(fourgrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec71d7c8-3a96-472f-b0d4-c640083458d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01867e0-4a76-48ab-ba73-2006d08004ad",
   "metadata": {},
   "source": [
    "### <center>Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f325d-ae98-4df4-9d74-37c045c359bd",
   "metadata": {},
   "source": [
    "##### BoW (мешок слов) подходит для задач анализа текста:\n",
    "- Классификация текста (например, спам/не спам);\n",
    "- Анализ тональности;\n",
    "- Вычисление сходства между текстами.\n",
    "\n",
    "##### Для генерации же текста требуются модели, которые могут учитывать последовательность слов, чтобы сохранить смысл:\n",
    "- Рекуррентные нейронные сети (RNN);\n",
    "- LSTM/GRU;\n",
    "- Трансформеры (например, GPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d706912b-9e71-4b64-82aa-dc67c1c8a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = np.array(list(bag_of_words.values())).reshape(-1, 1)\n",
    "Y_bow = np.arange(len(bag_of_words))\n",
    "lb = LabelBinarizer()\n",
    "Y_bow = lb.fit_transform(Y_bow)\n",
    "\n",
    "X_bow_train, X_bow_test, Y_bow_train, Y_bow_test = train_test_split(X_bow, Y_bow, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d262960-7194-4f46-a537-f303e28496ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.0000e+00 - loss: 9.5485 - val_accuracy: 0.0000e+00 - val_loss: 9.3475\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 9.2204 - val_accuracy: 0.0000e+00 - val_loss: 10.4675\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 8.8226 - val_accuracy: 0.0000e+00 - val_loss: 11.1296\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - accuracy: 0.0000e+00 - loss: 8.6826 - val_accuracy: 0.0000e+00 - val_loss: 11.5205\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 8.5696 - val_accuracy: 0.0000e+00 - val_loss: 11.3328\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.0000e+00 - loss: 8.4908 - val_accuracy: 0.0000e+00 - val_loss: 12.0298\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "dense_bow = create_dense_model(len(bag_of_words))\n",
    "dense_bow.fit(X_bow_train, Y_bow_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# dense_bow.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1912fd4f-701f-496d-8438-5d4267455822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Classification Metrics: {'Accuracy': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'F1-Score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "dense_bow_metrics = evaluate_model(dense_bow, X_bow_test, Y_bow_test, bow=True) # vocab=vocab for text_generation\n",
    "print(\"Classification Metrics:\", dense_bow_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134e2621-8edb-46ea-9fe4-fca9c16012c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "dense_generated_text = evaluate_model(dense_bow, X_bow_test, Y_bow_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/dense2.txt\", dense_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc4251-283f-4410-a00a-4cc9d29ceacc",
   "metadata": {},
   "source": [
    "### <center>2-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec3945-dba6-4379-8c28-8e66a4aae3ea",
   "metadata": {},
   "source": [
    "##### Данная задача - задача классификации с множественными классами, где классами являются все возможные слова в словаре, и задача сводится к предсказанию одного из этих классов (слова) на основе входной последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae52dfb1-6d4a-48e6-954c-65b22e3f1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bigrams = 2\n",
    "\n",
    "X_bigrams, Y_bigrams = prepare_data(bigrams_sequences, n_bigrams)\n",
    "X_bigrams = pad_sequences(X_bigrams, maxlen=n_bigrams-1, padding='pre')\n",
    "\n",
    "X_bigrams_train, X_bigrams_test, Y_bigrams_train, Y_bigrams_test = train_test_split(X_bigrams, Y_bigrams, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70cd0df1-407d-4edd-81d0-7fa2956f90b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 55ms/step - accuracy: 1.0764e-05 - loss: 9.2728 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 2.1349e-05 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2726\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 1.2246e-04 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 52ms/step - accuracy: 3.0303e-05 - loss: 9.2726 - val_accuracy: 0.0000e+00 - val_loss: 9.2725\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 3.2376e-05 - loss: 9.2725 - val_accuracy: 9.7714e-05 - val_loss: 9.2724\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 5.9304e-05 - loss: 9.2725 - val_accuracy: 9.7714e-05 - val_loss: 9.2724\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 4.3077e-05 - loss: 9.2724 - val_accuracy: 9.7714e-05 - val_loss: 9.2723\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 3.6564e-05 - loss: 9.2723 - val_accuracy: 9.7714e-05 - val_loss: 9.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 1.0297e-04 - loss: 9.2723 - val_accuracy: 9.7714e-05 - val_loss: 9.2722\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 1.0678e-04 - loss: 9.2723 - val_accuracy: 9.7714e-05 - val_loss: 9.2722\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "rnn_bigrams = create_rnn_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "rnn_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# rnn_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92243bcc-90b5-4cc9-ab2e-57470d5abc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.000156335495974361,\n",
       " 'Precision': 0.0003936812034990727,\n",
       " 'Recall': 0.000156335495974361,\n",
       " 'F1-Score': 0.00014859821380071463}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_bigrams_metrics = evaluate_model(rnn_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "rnn_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b449c33d-40d2-4826-8b56-e6454dcdfea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_bigrams_generated_text = evaluate_model(rnn_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/rnn_bigrams2.txt\", rnn_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6632164e-e85f-4500-b036-2dca7ab850ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 67ms/step - accuracy: 2.5541e-04 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 2.7618e-04 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 80ms/step - accuracy: 5.1781e-04 - loss: 9.2726 - val_accuracy: 1.9543e-04 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 66ms/step - accuracy: 7.2950e-04 - loss: 9.2726 - val_accuracy: 5.8628e-04 - val_loss: 9.2726\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 9.8164e-04 - loss: 9.2725 - val_accuracy: 0.0012 - val_loss: 9.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 68ms/step - accuracy: 0.0016 - loss: 9.2725 - val_accuracy: 0.0014 - val_loss: 9.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 67ms/step - accuracy: 0.0019 - loss: 9.2724 - val_accuracy: 0.0017 - val_loss: 9.2724\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.0021 - loss: 9.2724 - val_accuracy: 0.0021 - val_loss: 9.2724\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.0029 - loss: 9.2723 - val_accuracy: 0.0022 - val_loss: 9.2723\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.0028 - loss: 9.2723 - val_accuracy: 0.0025 - val_loss: 9.2723\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "lstm_bigrams = create_lstm_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "lstm_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# lstm_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5af3f1f-3251-42fc-87c5-ed800c6b85d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.002657703431564137,\n",
       " 'Precision': 0.00011909709346354223,\n",
       " 'Recall': 0.002657703431564137,\n",
       " 'F1-Score': 0.0002105985612532636}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_bigrams_metrics = evaluate_model(lstm_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "lstm_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273841e1-88fb-43f7-b53d-0a8956cd65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_bigrams_generated_text = evaluate_model(lstm_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/lstm_bigrams2.txt\", lstm_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a031cf5-a0cf-49f9-bc85-9e9ee41ca581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 66ms/step - accuracy: 1.2792e-04 - loss: 9.2727 - val_accuracy: 9.7714e-05 - val_loss: 9.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 1.5709e-04 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 2.9898e-04 - loss: 9.2726 - val_accuracy: 9.7714e-05 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 52ms/step - accuracy: 2.8418e-04 - loss: 9.2726 - val_accuracy: 1.9543e-04 - val_loss: 9.2726\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 5.2977e-04 - loss: 9.2725 - val_accuracy: 2.9314e-04 - val_loss: 9.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 52ms/step - accuracy: 3.9628e-04 - loss: 9.2725 - val_accuracy: 2.9314e-04 - val_loss: 9.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 7.9031e-04 - loss: 9.2724 - val_accuracy: 5.8628e-04 - val_loss: 9.2724\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.0013 - loss: 9.2724 - val_accuracy: 8.7942e-04 - val_loss: 9.2724\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 0.0011 - loss: 9.2723 - val_accuracy: 0.0014 - val_loss: 9.2723\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - accuracy: 0.0015 - loss: 9.2723 - val_accuracy: 0.0014 - val_loss: 9.2723\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "gru_bigrams = create_gru_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "gru_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# gru_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39b98dfe-b623-4460-a38e-d05f0faa9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.0014851872117564292,\n",
       " 'Precision': 0.0003633506674284358,\n",
       " 'Recall': 0.0014851872117564292,\n",
       " 'F1-Score': 0.0003994968006347388}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_bigrams_metrics = evaluate_model(gru_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "gru_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "398ba264-73e0-4407-9c56-5ac709c6eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_bigrams_generated_text = evaluate_model(gru_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/gru_bigrams2.txt\", gru_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05723209-9abc-4e09-b6f2-636869453459",
   "metadata": {},
   "source": [
    "### <center>4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48c170af-3ed4-4245-b3a0-2022b72873d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fougrams = 4\n",
    "\n",
    "X_fourgrams, Y_fourgrams = prepare_data(fourgrams_sequences, n_fougrams)\n",
    "X_fourgrams = pad_sequences(X_fourgrams, maxlen=n_fougrams-1, padding='pre')\n",
    "\n",
    "X_fourgrams_train, X_fourgrams_test, Y_fourgrams_train, Y_fourgrams_test = train_test_split(X_fourgrams, Y_fourgrams, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "167516d2-f861-4d6a-b3c0-dff0b9727981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 4.5575e-05 - loss: 9.2728 - val_accuracy: 9.7714e-05 - val_loss: 9.2728\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 1.3178e-04 - loss: 9.2727 - val_accuracy: 9.7714e-05 - val_loss: 9.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 5.7720e-05 - loss: 9.2726 - val_accuracy: 9.7714e-05 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 48ms/step - accuracy: 9.7796e-05 - loss: 9.2725 - val_accuracy: 9.7714e-05 - val_loss: 9.2726\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 1.4434e-04 - loss: 9.2725 - val_accuracy: 9.7714e-05 - val_loss: 9.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 1.5980e-04 - loss: 9.2724 - val_accuracy: 1.9543e-04 - val_loss: 9.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 48ms/step - accuracy: 2.6560e-04 - loss: 9.2723 - val_accuracy: 1.9543e-04 - val_loss: 9.2724\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 1.2688e-04 - loss: 9.2723 - val_accuracy: 1.9543e-04 - val_loss: 9.2724\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 48ms/step - accuracy: 2.5630e-04 - loss: 9.2722 - val_accuracy: 1.9543e-04 - val_loss: 9.2723\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 48ms/step - accuracy: 2.9629e-04 - loss: 9.2721 - val_accuracy: 1.9543e-04 - val_loss: 9.2722\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "rnn_fourgrams = create_rnn_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "rnn_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# rnn_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34d84cc1-5a7b-4572-b406-171e2abf69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.00031269543464665416,\n",
       " 'Precision': 0.001027917667840646,\n",
       " 'Recall': 0.00031269543464665416,\n",
       " 'F1-Score': 0.00044506983531373775}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_fourgrams_metrics = evaluate_model(rnn_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "rnn_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0432fc61-5b38-4fab-ad40-9c1c88e0d4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_fourgrams_generated_text = evaluate_model(rnn_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/rnn_fourgrams2.txt\", rnn_fourgrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95f16a2b-129d-411e-bbd6-f5ab5f1740b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 1.0345e-04 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 49ms/step - accuracy: 7.2191e-05 - loss: 9.2727 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 1.3457e-04 - loss: 9.2726 - val_accuracy: 1.9543e-04 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 2.6222e-04 - loss: 9.2726 - val_accuracy: 6.8399e-04 - val_loss: 9.2726\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 6.0570e-04 - loss: 9.2725 - val_accuracy: 9.7714e-04 - val_loss: 9.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 9.5154e-04 - loss: 9.2725 - val_accuracy: 0.0014 - val_loss: 9.2725\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.0013 - loss: 9.2724 - val_accuracy: 0.0019 - val_loss: 9.2724\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 0.0017 - loss: 9.2724 - val_accuracy: 0.0021 - val_loss: 9.2724\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.0020 - loss: 9.2723 - val_accuracy: 0.0025 - val_loss: 9.2723\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.0020 - loss: 9.2723 - val_accuracy: 0.0026 - val_loss: 9.2723\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "lstm_fourgrams = create_lstm_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "lstm_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# lstm_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b2af265-34e4-4ca9-9e4d-66249aafc0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.002892432770481551,\n",
       " 'Precision': 0.0005741623735609098,\n",
       " 'Recall': 0.002892432770481551,\n",
       " 'F1-Score': 0.0005618836955201098}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_fourgrams_metrics = evaluate_model(lstm_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "lstm_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3deb4010-83a7-459e-a2a8-3254506eeace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_fourgrams_generated_text = evaluate_model(lstm_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/lstm_fourgrams2.txt\", lstm_fourgrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c0d070a-de4c-47e2-96eb-586e47bf4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 8.4824e-05 - loss: 9.2728 - val_accuracy: 9.7714e-05 - val_loss: 9.2727\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 6.4699e-05 - loss: 9.2727 - val_accuracy: 1.9543e-04 - val_loss: 9.2727\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 1.3870e-04 - loss: 9.2726 - val_accuracy: 1.9543e-04 - val_loss: 9.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 1.8639e-04 - loss: 9.2726 - val_accuracy: 1.9543e-04 - val_loss: 9.2725\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 2.6536e-04 - loss: 9.2725 - val_accuracy: 3.9085e-04 - val_loss: 9.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 2.7259e-04 - loss: 9.2725 - val_accuracy: 3.9085e-04 - val_loss: 9.2724\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 6.3853e-04 - loss: 9.2724 - val_accuracy: 8.7942e-04 - val_loss: 9.2724\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 7.6554e-04 - loss: 9.2723 - val_accuracy: 0.0014 - val_loss: 9.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 7.1224e-04 - loss: 9.2723 - val_accuracy: 0.0015 - val_loss: 9.2723\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.0011 - loss: 9.2722 - val_accuracy: 0.0015 - val_loss: 9.2722\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "gru_fourgrams = create_gru_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "gru_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# gru_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc2e8b41-ef09-4bc1-a096-54e0d17ed127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.0013289555972482803,\n",
       " 'Precision': 0.0004056128002203461,\n",
       " 'Recall': 0.0013289555972482803,\n",
       " 'F1-Score': 0.00046798474193111416}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_fourgrams_metrics = evaluate_model(gru_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "gru_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d64915f-b061-4f45-8da5-18ce60202538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_fourgrams_generated_text = evaluate_model(gru_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/gru_fourgrams2.txt\", gru_fourgrams_generated_text['Generated Text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
