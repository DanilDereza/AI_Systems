{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462f8d49-34a7-4448-8478-11e16aeeb003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout, Bidirectional, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2828b0-48f8-45e2-8a72-60d43730f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92f8777-1d20-4f17-8460-3d2ffa98a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    bag_of_words = data[\"BoW\"]\n",
    "    bigrams = data[\"bigrams\"]\n",
    "    fourgrams = data[\"fourgrams\"]\n",
    "    return bag_of_words, bigrams, fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de648da-7377-41b0-94dd-68822b36c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(bag_of_words):  # создает словарь vocab, который сопоставляет каждому слову уникальный индекс\n",
    "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(bag_of_words.items())}\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def convert_to_sequences(ngrams, vocab): # преобразует n-граммы в последовательности индексов, основываясь на словаре vocab\n",
    "    sequences = []\n",
    "    for gram in ngrams:\n",
    "        if all(word in vocab for word in gram):\n",
    "            sequences.append([vocab[word] for word in gram])\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def prepare_data(ngrams_sequences, n):\n",
    "    '''\n",
    "    X - все элементы в n-грамме кроме последнего\n",
    "    Y - последнее слово в n-грамме\n",
    "    '''\n",
    "    X, Y = [], []\n",
    "    for gram in ngrams_sequences:\n",
    "        X.append(gram[:-1])\n",
    "        Y.append(gram[-1])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d37823f-48a4-4928-b519-c318ac3212a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer=['rmsprop', 'adam', 'adagrad', 'adadelta', 'ftrl', 'sgd' (SGD(learning_rate=0.01, momentum=0.9))]\n",
    "# loss=['sparse_categorical_crossentropy']\n",
    "\n",
    "\n",
    "def create_rnn_model(vocab_size, embedding_dim, n):\n",
    "    layers = []\n",
    "    layers.append(Embedding( # Embedding - преобразовает каждое слово или токен в вектор размерности output_dim\n",
    "        input_dim=vocab_size, # input_dim - количество уникальных токенов (размер словаря)\n",
    "        output_dim=embedding_dim, # output_dim - размерность векторов, в которые будет кодироваться каждое слово\n",
    "        input_length=n-1 # input_length - длина входной последовательности из n-1 токенов для N-грамм\n",
    "    ))\n",
    "    layers.append(Bidirectional(SimpleRNN(\n",
    "        256,\n",
    "        activation=\"tanh\",\n",
    "        return_sequences=False,\n",
    "        kernel_regularizer=l2(0.01)\n",
    "    )))\n",
    "    layers.append(Dropout(0.9)) # слой регуляризации в нейронной сети, отключающий указанный процент нейронов, предотвращая переобучение\n",
    "    layers.append(Dense(vocab_size, activation='softmax')) # полносвязный выходной слой\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lstm_model(vocab_size, embedding_dim, n):\n",
    "    layers = []\n",
    "    layers.append(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=n-1\n",
    "    ))\n",
    "    layers.append(Bidirectional(LSTM(\n",
    "        256, \n",
    "        activation=\"tanh\", \n",
    "        return_sequences=False, \n",
    "        kernel_regularizer=l2(0.01)\n",
    "    )))\n",
    "    layers.append(Dropout(0.9))\n",
    "    layers.append(Dense(vocab_size, activation='softmax'))\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_gru_model(vocab_size, embedding_dim, n):\n",
    "    layers = []\n",
    "    layers.append(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=n-1\n",
    "    ))\n",
    "    layers.append(Bidirectional(GRU(\n",
    "        256,\n",
    "        activation=\"tanh\",\n",
    "        return_sequences=False,\n",
    "        kernel_regularizer=l2(0.01)\n",
    "    )))\n",
    "    layers.append(Dropout(0.9))\n",
    "    layers.append(Dense(vocab_size, activation='softmax'))\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    # momentum - добавляет к обновлению текущих параметров компоненту, зависящую от \"накопленного\" направления движения, чтобы быстрее преодолевать плоскости и локальные минимумы\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_dense_model(vocab_size):\n",
    "    model = Sequential([\n",
    "        Dense(512, input_dim=1, activation='tanh'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6882d36-6045-4cc0-9c50-73f791ab1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, vocab=None, threshold=None, bow=False):\n",
    "    preds = model.predict(X_test)\n",
    "    if threshold:\n",
    "        preds_binary = (preds > threshold).astype(np.int32)\n",
    "    else:\n",
    "        preds_binary = preds.argmax(axis=-1)\n",
    "\n",
    "    metrics = {}\n",
    "    if vocab: # Если доступен словарь, метрики для текста\n",
    "        inv_vocab = {idx: word for word, idx in vocab.items()}\n",
    "        preds_text = [inv_vocab.get(idx, \"<UNK>\") for idx in preds_binary]\n",
    "        metrics[\"Generated Text\"] = \" \".join(preds_text)\n",
    "    else: # Для классификации\n",
    "        if bow: Y_test = Y_test.argmax(axis=-1)\n",
    "        metrics.update({\n",
    "            \"Accuracy\": accuracy_score(Y_test, preds_binary),  # Убираем argmax\n",
    "            \"Precision\": precision_score(Y_test, preds_binary, average='weighted'),\n",
    "            \"Recall\": recall_score(Y_test, preds_binary, average='weighted'),\n",
    "            \"F1-Score\": f1_score(Y_test, preds_binary, average='weighted'),\n",
    "        })\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5de7999-1637-45af-8e06-16d9adfe4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99ce5f0-3fc9-482c-9002-1c3de6e249e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: [('человек', 369), ('время', 266), ('корабль', 254), ('сторона', 208), ('новый', 205), ('рука', 196), ('планета', 193), ('два', 191), ('сказать', 190), ('дело', 187)]\n",
      "\n",
      "2-граммы: [('алекс', 'каменев'), ('каменев', 'макс'), ('макс', 'вольф'), ('вольф', 'наёмник'), ('наёмник', 'глава'), ('глава', 'станция'), ('станция', 'технический'), ('технический', 'обслуживание'), ('обслуживание', 'лиманский'), ('лиманский', 'союз')]\n",
      "\n",
      "4-граммы: [('алекс', 'каменев', 'макс', 'вольф'), ('каменев', 'макс', 'вольф', 'наёмник'), ('макс', 'вольф', 'наёмник', 'глава'), ('вольф', 'наёмник', 'глава', 'станция'), ('наёмник', 'глава', 'станция', 'технический'), ('глава', 'станция', 'технический', 'обслуживание'), ('станция', 'технический', 'обслуживание', 'лиманский'), ('технический', 'обслуживание', 'лиманский', 'союз'), ('обслуживание', 'лиманский', 'союз', 'приграничный'), ('лиманский', 'союз', 'приграничный', 'территория')]\n"
     ]
    }
   ],
   "source": [
    "path = \"result_lab2/text_structures1.pkl\"\n",
    "bag_of_words, bigrams, fourgrams = load_data(path)\n",
    "\n",
    "print(\"BoW:\", list(bag_of_words.items())[:10])\n",
    "print(\"\\n2-граммы:\", bigrams[:10])\n",
    "print(\"\\n4-граммы:\", fourgrams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d954900-3f3a-4646-a369-292e9414a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Словарь: [('человек', 1), ('время', 2), ('корабль', 3), ('сторона', 4), ('новый', 5), ('рука', 6), ('планета', 7), ('два', 8), ('сказать', 9), ('дело', 10)]\n"
     ]
    }
   ],
   "source": [
    "vocab = create_vocab(bag_of_words)\n",
    "vocab_size = len(vocab) + 1\n",
    "print(\"\\nСловарь:\", list(vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e9014a-336c-4138-ac5b-85bb0a12461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_sequences = convert_to_sequences(bigrams, vocab)\n",
    "fourgrams_sequences = convert_to_sequences(fourgrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2459e0-3efb-4dca-bb1e-89d9005c217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True, # восстанавливает веса модели из эпохи с наилучшим значением контролируемой величины\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e2dce-37ef-46ac-9901-eca0d974d56c",
   "metadata": {},
   "source": [
    "### <center>Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e9cda-ee38-4eb6-89d8-d331f97687c6",
   "metadata": {},
   "source": [
    "##### BoW (мешок слов) подходит для задач анализа текста:\n",
    "- Классификация текста (например, спам/не спам);\n",
    "- Анализ тональности;\n",
    "- Вычисление сходства между текстами.\n",
    "\n",
    "##### Для генерации же текста требуются модели, которые могут учитывать последовательность слов, чтобы сохранить смысл:\n",
    "- Рекуррентные нейронные сети (RNN);\n",
    "- LSTM/GRU;\n",
    "- Трансформеры (например, GPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e74ed44-a944-4bee-b0cc-e63e9f5fcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = np.array(list(bag_of_words.values())).reshape(-1, 1)\n",
    "Y_bow = np.arange(len(bag_of_words))\n",
    "lb = LabelBinarizer() # one-hot кодирование Y_bow\n",
    "Y_bow = lb.fit_transform(Y_bow)\n",
    "\n",
    "X_bow_train, X_bow_test, Y_bow_train, Y_bow_test = train_test_split(X_bow, Y_bow, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e705059-9cf2-4962-87bf-73460a345c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.0000e+00 - loss: 9.4888 - val_accuracy: 0.0000e+00 - val_loss: 9.4869\n",
      "Epoch 2/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.0000e+00 - loss: 9.3983 - val_accuracy: 0.0000e+00 - val_loss: 9.5335\n",
      "Epoch 3/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.0000e+00 - loss: 9.3506 - val_accuracy: 0.0000e+00 - val_loss: 9.5554\n",
      "Epoch 4/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - accuracy: 0.0000e+00 - loss: 9.3355 - val_accuracy: 0.0000e+00 - val_loss: 9.5640\n",
      "Epoch 5/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.0000e+00 - loss: 9.3172 - val_accuracy: 0.0000e+00 - val_loss: 9.5814\n",
      "Epoch 6/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.0000e+00 - loss: 9.2884 - val_accuracy: 0.0000e+00 - val_loss: 9.6183\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "dense_bow = create_dense_model(len(bag_of_words)) # vocab_siza=len(bag_of_words)\n",
    "dense_bow.fit(X_bow_train, Y_bow_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# dense_bow.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abc1361a-6a94-4fb5-b44d-9db097102201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Classification Metrics: {'Accuracy': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'F1-Score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "dense_bow_metrics = evaluate_model(dense_bow, X_bow_test, Y_bow_test, bow=True) # vocab=vocab for text_generation\n",
    "print(\"Classification Metrics:\", dense_bow_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94923e7-1d8f-4a0f-927d-9c3525c70448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "dense_generated_text = evaluate_model(dense_bow, X_bow_test, Y_bow_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/dense1.txt\", dense_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec65fc48-ece7-4345-9be4-6fe0c0b422bb",
   "metadata": {},
   "source": [
    "### <center>2-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f02971-8a3b-4faf-b2d3-f037ab59cefa",
   "metadata": {},
   "source": [
    "##### Данная задача - задача классификации с множественными классами, где классами являются все возможные слова в словаре, и задача сводится к предсказанию одного из этих классов (слова) на основе входной последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0153aa20-6025-4cef-8eb1-dd4e2aea9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bigrams = 2\n",
    "\n",
    "X_bigrams, Y_bigrams = prepare_data(bigrams_sequences, n_bigrams)\n",
    "X_bigrams = pad_sequences(X_bigrams, maxlen=n_bigrams-1, padding='pre')\n",
    "\n",
    "X_bigrams_train, X_bigrams_test, Y_bigrams_train, Y_bigrams_test = train_test_split(X_bigrams, Y_bigrams, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80542ce-14c5-44da-ad14-888a9fa252d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 92ms/step - accuracy: 8.0077e-05 - loss: 11.1244 - val_accuracy: 9.7761e-05 - val_loss: 11.1006\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 91ms/step - accuracy: 2.6737e-04 - loss: 11.0920 - val_accuracy: 9.7761e-05 - val_loss: 11.0647\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 88ms/step - accuracy: 1.4258e-04 - loss: 11.0554 - val_accuracy: 9.7761e-05 - val_loss: 11.0273\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 92ms/step - accuracy: 7.7216e-06 - loss: 11.0178 - val_accuracy: 9.7761e-05 - val_loss: 10.9895\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 95ms/step - accuracy: 1.8565e-04 - loss: 10.9804 - val_accuracy: 9.7761e-05 - val_loss: 10.9520\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 94ms/step - accuracy: 2.9540e-04 - loss: 10.9427 - val_accuracy: 9.7761e-05 - val_loss: 10.9152\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 89ms/step - accuracy: 7.2120e-05 - loss: 10.9059 - val_accuracy: 9.7761e-05 - val_loss: 10.8790\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 88ms/step - accuracy: 1.5839e-04 - loss: 10.8700 - val_accuracy: 9.7761e-05 - val_loss: 10.8437\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 98ms/step - accuracy: 2.2316e-05 - loss: 10.8350 - val_accuracy: 9.7761e-05 - val_loss: 10.8091\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 91ms/step - accuracy: 1.2134e-04 - loss: 10.8008 - val_accuracy: 9.7761e-05 - val_loss: 10.7754\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "rnn_bigrams = create_rnn_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "rnn_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# rnn_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66e3bc1d-7586-4952-ba81-06c19d06cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.00015642108556233381,\n",
       " 'Precision': 7.821054278116691e-05,\n",
       " 'Recall': 0.00015642108556233381,\n",
       " 'F1-Score': 0.00010428072370822252}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_bigrams_metrics = evaluate_model(rnn_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "rnn_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac80ccce-55d2-4e73-9d63-b5c2b27565cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_bigrams_generated_text = evaluate_model(rnn_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/rnn_bigrams1.txt\", rnn_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043acbfb-8740-4810-9c1d-1961a503eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 105ms/step - accuracy: 2.7847e-05 - loss: 11.3561 - val_accuracy: 9.7761e-05 - val_loss: 11.3221\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 104ms/step - accuracy: 1.8796e-04 - loss: 11.3104 - val_accuracy: 0.0000e+00 - val_loss: 11.2753\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 101ms/step - accuracy: 8.7564e-05 - loss: 11.2637 - val_accuracy: 9.7761e-05 - val_loss: 11.2293\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 100ms/step - accuracy: 9.7955e-05 - loss: 11.2180 - val_accuracy: 6.8433e-04 - val_loss: 11.1844\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 106ms/step - accuracy: 8.9128e-05 - loss: 11.1734 - val_accuracy: 9.7761e-04 - val_loss: 11.1406\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 107ms/step - accuracy: 4.2318e-04 - loss: 11.1298 - val_accuracy: 0.0017 - val_loss: 11.0979\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 98ms/step - accuracy: 1.8388e-04 - loss: 11.0874 - val_accuracy: 0.0025 - val_loss: 11.0563\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 99ms/step - accuracy: 4.4009e-04 - loss: 11.0461 - val_accuracy: 0.0031 - val_loss: 11.0157\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 96ms/step - accuracy: 4.5134e-04 - loss: 11.0058 - val_accuracy: 0.0042 - val_loss: 10.9762\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 99ms/step - accuracy: 6.1475e-04 - loss: 10.9664 - val_accuracy: 0.0048 - val_loss: 10.9376\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "lstm_bigrams = create_lstm_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "lstm_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# lstm_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ecf5a3e-90b7-4aca-a4b7-a08911bb39c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.0035976849679336775,\n",
       " 'Precision': 0.00024365699624623495,\n",
       " 'Recall': 0.0035976849679336775,\n",
       " 'F1-Score': 0.000347552749453942}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_bigrams_metrics = evaluate_model(lstm_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "lstm_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51965b9e-8bbb-4c6e-9594-1f66b7423729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_bigrams_generated_text = evaluate_model(lstm_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/lstm_bigrams1.txt\", lstm_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbfe44e1-2bcc-4818-81e9-b37cd9958023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 104ms/step - accuracy: 8.8286e-05 - loss: 11.3123 - val_accuracy: 9.7761e-05 - val_loss: 11.2800\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 97ms/step - accuracy: 2.1685e-04 - loss: 11.2688 - val_accuracy: 9.7761e-05 - val_loss: 11.2349\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 99ms/step - accuracy: 2.5850e-04 - loss: 11.2237 - val_accuracy: 9.7761e-05 - val_loss: 11.1901\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 96ms/step - accuracy: 1.3357e-04 - loss: 11.1791 - val_accuracy: 3.9105e-04 - val_loss: 11.1463\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 93ms/step - accuracy: 9.3539e-05 - loss: 11.1355 - val_accuracy: 3.9105e-04 - val_loss: 11.1035\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 96ms/step - accuracy: 2.9442e-05 - loss: 11.0930 - val_accuracy: 4.8881e-04 - val_loss: 11.0618\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 100ms/step - accuracy: 4.8341e-05 - loss: 11.0516 - val_accuracy: 6.8433e-04 - val_loss: 11.0211\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 112ms/step - accuracy: 8.7790e-05 - loss: 11.0111 - val_accuracy: 0.0012 - val_loss: 10.9815\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 117ms/step - accuracy: 5.9531e-06 - loss: 10.9717 - val_accuracy: 0.0017 - val_loss: 10.9429\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 108ms/step - accuracy: 3.6850e-06 - loss: 10.9334 - val_accuracy: 0.0019 - val_loss: 10.9052\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "gru_bigrams = create_gru_model(vocab_size, EMBEDDING_DIM, n_bigrams)\n",
    "gru_bigrams.fit(X_bigrams_train, Y_bigrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# gru_bigrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ee69ea-aa00-4d69-981a-353ba9e6884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.0014860003128421711,\n",
       " 'Precision': 0.001123339616004915,\n",
       " 'Recall': 0.0014860003128421711,\n",
       " 'F1-Score': 0.0006895544119675449}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_bigrams_metrics = evaluate_model(gru_bigrams, X_bigrams_test, Y_bigrams_test) # vocab=vocab for text_generation\n",
    "gru_bigrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89327f73-25b1-4b32-b5da-9ab88e08b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_bigrams_generated_text = evaluate_model(gru_bigrams, X_bigrams_test, Y_bigrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/gru_bigrams1.txt\", gru_bigrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09dbed-9892-443d-a0f5-f8909d632232",
   "metadata": {},
   "source": [
    "### <center>4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "009b2813-e141-49c9-8b19-148c46952944",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fougrams = 4\n",
    "\n",
    "X_fourgrams, Y_fourgrams = prepare_data(fourgrams_sequences, n_fougrams)\n",
    "X_fourgrams = pad_sequences(X_fourgrams, maxlen=n_fougrams-1, padding='pre')\n",
    "\n",
    "X_fourgrams_train, X_fourgrams_test, Y_fourgrams_train, Y_fourgrams_test = train_test_split(X_fourgrams, Y_fourgrams, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbb9526c-363f-41f4-952c-edf41ed66b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 103ms/step - accuracy: 8.6354e-05 - loss: 11.1094 - val_accuracy: 9.7761e-05 - val_loss: 11.0862\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 97ms/step - accuracy: 9.0674e-05 - loss: 11.0780 - val_accuracy: 9.7761e-05 - val_loss: 11.0514\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 94ms/step - accuracy: 2.4497e-05 - loss: 11.0428 - val_accuracy: 9.7761e-05 - val_loss: 11.0151\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 99ms/step - accuracy: 1.3396e-04 - loss: 11.0064 - val_accuracy: 9.7761e-05 - val_loss: 10.9787\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 102ms/step - accuracy: 3.5482e-05 - loss: 10.9701 - val_accuracy: 9.7761e-05 - val_loss: 10.9426\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 100ms/step - accuracy: 0.0000e+00 - loss: 10.9339 - val_accuracy: 1.9552e-04 - val_loss: 10.9070\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 107ms/step - accuracy: 1.2580e-04 - loss: 10.8983 - val_accuracy: 1.9552e-04 - val_loss: 10.8722\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 103ms/step - accuracy: 1.3937e-04 - loss: 10.8640 - val_accuracy: 1.9552e-04 - val_loss: 10.8381\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 104ms/step - accuracy: 5.4584e-05 - loss: 10.8302 - val_accuracy: 2.9328e-04 - val_loss: 10.8048\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 105ms/step - accuracy: 7.9662e-05 - loss: 10.7970 - val_accuracy: 2.9328e-04 - val_loss: 10.7722\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "rnn_fourgrams = create_rnn_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "rnn_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# rnn_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843e1e44-56b7-4725-aa5e-a91ca39c834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.00015642108556233381,\n",
       " 'Precision': 0.0006061317065540435,\n",
       " 'Recall': 0.00015642108556233381,\n",
       " 'F1-Score': 0.0002144482624644899}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_fourgrams_metrics = evaluate_model(rnn_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "rnn_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d441882-a6e6-4b52-b7f4-c4db43de4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_fourgrams_generated_text = evaluate_model(rnn_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/rnn_fourgrams1.txt\", rnn_fourgrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e8dd09-2482-41d0-9418-f7e3ada2d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 117ms/step - accuracy: 1.2102e-04 - loss: 11.3401 - val_accuracy: 1.9552e-04 - val_loss: 11.3063\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 115ms/step - accuracy: 2.8107e-05 - loss: 11.2947 - val_accuracy: 2.9328e-04 - val_loss: 11.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 118ms/step - accuracy: 7.2861e-05 - loss: 11.2485 - val_accuracy: 2.9328e-04 - val_loss: 11.2144\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 119ms/step - accuracy: 2.1739e-04 - loss: 11.2031 - val_accuracy: 3.9105e-04 - val_loss: 11.1698\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 117ms/step - accuracy: 4.8011e-05 - loss: 11.1589 - val_accuracy: 4.8881e-04 - val_loss: 11.1264\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 115ms/step - accuracy: 1.6542e-04 - loss: 11.1157 - val_accuracy: 7.8209e-04 - val_loss: 11.0841\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 101ms/step - accuracy: 2.0279e-04 - loss: 11.0736 - val_accuracy: 0.0011 - val_loss: 11.0428\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 101ms/step - accuracy: 6.9963e-05 - loss: 11.0327 - val_accuracy: 0.0016 - val_loss: 11.0026\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 102ms/step - accuracy: 1.5570e-04 - loss: 10.9927 - val_accuracy: 0.0020 - val_loss: 10.9634\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 102ms/step - accuracy: 3.0827e-04 - loss: 10.9537 - val_accuracy: 0.0029 - val_loss: 10.9252\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "lstm_fourgrams = create_lstm_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "lstm_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# lstm_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3373c6b4-3ffb-4e8f-9c61-fa201b12cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.00328484279680901,\n",
       " 'Precision': 0.00018336088323292945,\n",
       " 'Recall': 0.00328484279680901,\n",
       " 'F1-Score': 0.00032340798588227453}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_fourgrams_metrics = evaluate_model(lstm_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "lstm_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a53fddcf-4efd-498a-b4ce-e46b050c4d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_fourgrams_generated_text = evaluate_model(lstm_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/lstm_fourgrams1.txt\", lstm_fourgrams_generated_text['Generated Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27437718-5705-4541-ac5d-120d91c68c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 100ms/step - accuracy: 2.3892e-05 - loss: 11.3271 - val_accuracy: 0.0000e+00 - val_loss: 11.2946\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 99ms/step - accuracy: 7.4407e-05 - loss: 11.2833 - val_accuracy: 0.0000e+00 - val_loss: 11.2491\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 102ms/step - accuracy: 7.8792e-05 - loss: 11.2378 - val_accuracy: 0.0000e+00 - val_loss: 11.2040\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 103ms/step - accuracy: 6.7165e-05 - loss: 11.1929 - val_accuracy: 0.0000e+00 - val_loss: 11.1599\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 99ms/step - accuracy: 7.4020e-05 - loss: 11.1490 - val_accuracy: 0.0000e+00 - val_loss: 11.1168\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 99ms/step - accuracy: 2.3519e-05 - loss: 11.1062 - val_accuracy: 9.7761e-05 - val_loss: 11.0747\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 103ms/step - accuracy: 1.0465e-04 - loss: 11.0644 - val_accuracy: 9.7761e-05 - val_loss: 11.0338\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 100ms/step - accuracy: 1.1246e-04 - loss: 11.0237 - val_accuracy: 2.9328e-04 - val_loss: 10.9938\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 106ms/step - accuracy: 1.9270e-04 - loss: 10.9840 - val_accuracy: 5.8657e-04 - val_loss: 10.9549\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 102ms/step - accuracy: 6.0506e-05 - loss: 10.9453 - val_accuracy: 6.8433e-04 - val_loss: 10.9169\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "gru_fourgrams = create_gru_model(vocab_size, EMBEDDING_DIM, n_fougrams)\n",
    "gru_fourgrams.fit(X_fourgrams_train, Y_fourgrams_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping]);\n",
    "# gru_fourgrams.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "227b69eb-f60b-4088-b052-09dcc9e5661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.0009385265133740028,\n",
       " 'Precision': 0.00022495106164470955,\n",
       " 'Recall': 0.0009385265133740028,\n",
       " 'F1-Score': 0.0003123731889811509}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_fourgrams_metrics = evaluate_model(gru_fourgrams, X_fourgrams_test, Y_fourgrams_test) # vocab=vocab for text_generation\n",
    "gru_fourgrams_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fb31c25-18b7-463d-89bd-d755fb7284aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_fourgrams_generated_text = evaluate_model(gru_fourgrams, X_fourgrams_test, Y_fourgrams_test, vocab=vocab, bow=True) # vocab=vocab for text_generation\n",
    "save_text(\"generated_texts/gru_fourgrams1.txt\", gru_fourgrams_generated_text['Generated Text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
